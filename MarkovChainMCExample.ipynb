{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca51a72a",
   "metadata": {},
   "source": [
    "# A Markov chain monte carlo example\n",
    "\n",
    "In the lecures we saw how to calculate a posterior distribution using Bayes' theorem. Remember, that for a continuous parameter $\\theta$, \n",
    "\n",
    "$$\n",
    "p(\\theta|X) = \\frac{p(X|\\theta)p(\\theta)}{p(X)}\n",
    "$$\n",
    "\n",
    "where $X$ represents our data, $p(\\theta)$ is the *prior* probabillity of $\\theta$, and $p(X)=\\int p(\\theta|X)d\\theta$. \n",
    "\n",
    "To make statistical statements about the parameter $\\theta$, we need to know the posterior probabity distribution $p(\\theta|X)$. It is often the case (when the dataset is large or the probability model complex) that rather than calculate the posterior directly, we use monte carlo simulations to extract properties of the posterior distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a4ca1",
   "metadata": {},
   "source": [
    "Let's take a simple example where $X\\sim \\phi(\\theta,1)$ - is normally distributed and $p(\\theta)=phi(0.5,2)$. Suppose our data is represented by a single measurement of $X=1.2$.\n",
    "\n",
    "Our prior is now \n",
    "\n",
    "$$\n",
    "p(\\theta)\\propto e^{-\\frac{1}{2}\\frac{(\\theta-0.5)^{2}}{2^{2}}}\n",
    "$$\n",
    "\n",
    "and the *likelihood*  is, \n",
    "\n",
    "$$\n",
    "p(X|\\theta)\\propto e^{-\\frac{1}{2}\\frac{(1.2-\\theta)^{2}}{1^{2}}}\n",
    "$$\n",
    "\n",
    "where we've ignored  the normalisation terms. \n",
    "\n",
    "We can quickly calculate the posterior probability using the `scipy.stats.norm.pdf` method (which yields the probability density of a normal distribution) and since we need to integrate, we'll use the numerical integration `scipy.integrate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced29640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "xmeas = 1.2\n",
    "\n",
    "def prior(th): \n",
    "    return stats.norm.pdf(th,0.5,2)\n",
    "\n",
    "def likelihood(th):\n",
    "    return stats.norm.pdf(xmeas,th,1)\n",
    "\n",
    "def posterior(th):\n",
    "    return likelihood(th)*prior(th)\n",
    "\n",
    "pX = integrate.quad(posterior,-8,8)[0]\n",
    "\n",
    "thvals = numpy.linspace(-5,5,100)\n",
    "post   = [posterior(th)/pX for th in thvals]\n",
    "plt.plot(thvals,post,color='red')\n",
    "plt.xlabel(\"$\\\\theta$\")\n",
    "plt.ylabel(\"$p(\\\\theta|X)$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77f7f0",
   "metadata": {},
   "source": [
    "## A basic MC approach\n",
    "\n",
    "We can see that (as expected) the posterior is centered around our measured value of $X=1.2$. \n",
    "\n",
    "We could obtain the same distribution using monte carlo simulation as follows: \n",
    "\n",
    "   * First we randomly pick values of $\\theta\\rightarrow \\theta'$, according to our prior $p(\\theta)$. \n",
    "   * Decide whether to keep the value generated according to the likelihood. \n",
    "       * Generate a uniform random value $r\\sim U(0,1)$\n",
    "       * Keep the generated value of $\\theta$ if $r<p(X|\\theta\\prime)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcprior = numpy.random.normal(0.5,2,10000)\n",
    "\n",
    "# I'm using a for loop in python! It's ok because it makes the steps easy to read\n",
    "accepted_mc = []\n",
    "for mcp in mcprior :\n",
    "    rnd = numpy.random.uniform(0,1)\n",
    "    plike = likelihood(mcp)\n",
    "    if rnd < plike: accepted_mc.append(mcp)\n",
    "\n",
    "plt.hist(accepted_mc,density=True,fill=False,edgecolor='blue')\n",
    "plt.plot(thvals,post,color='red')\n",
    "plt.xlabel(\"$\\\\theta$\")\n",
    "plt.ylabel(\"$p(\\\\theta|X)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852bf17a",
   "metadata": {},
   "source": [
    "The resulting distribution of values which are kept approximates the posterior distribution, as can be seen by the fact that the red line (the posterior distribution we calcuated before) matches the histogram. \n",
    "\n",
    "From the passing samples, we can calculate things like the mean of the posterior, or quantile ranges, that can be used for making statements about $\\theta$. \n",
    "\n",
    "Note however, that although we generated 10,000 samples,  the number of entries  in the histogram is much less due to the acceptance step. In fact, the efficiency of the acceptance is quite low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fraction of accepted samples\",  float(len(accepted_mc))/len(mcprior))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8d5b2",
   "metadata": {},
   "source": [
    "This would be very inefficient for large dimensional data spaces or more complicated likelihoods. Thankfully we can improve things using a  markov chain approach..\n",
    "\n",
    "## A Markov chain approach and Metropolis-Hastings\n",
    "\n",
    "A Markov chain MC is any MC proccess where each step is dependent on the current position. \n",
    "\n",
    "In our simple MC, each step was completely independent of one another (the random values of $\\theta$ were independent). \n",
    "\n",
    "In the Metropolis-Hastings algorithm, we modify the algorithm to accept or reject a  proposed value for the parameter based on the ratios of the posterior probability between the current value of the parameter ($\\theta$) and the proposed one ($\\theta_{\\text{new}}$). We define the ratio, \n",
    "\n",
    "$$\n",
    "r(\\theta_{\\text{new}},\\theta) = \\frac{p(\\theta_{\\text{new}}|X)}{p(\\theta|X)} = \\frac{p(X|\\theta_{\\text{new}})p(\\theta_{\\text{new}})}{p(X|\\theta)p(\\theta)}\n",
    "$$\n",
    "\n",
    "Note that there is no need to normalise this since the normalisation term $p(X)$ cancels in the ratio. \n",
    "\n",
    "The decision to accept or reject the value will be determined by the value of $r$. \n",
    "\n",
    "  * if $r>1$ - accept $\\theta_{new}$ \n",
    "  * else \n",
    "     * define $alpha = min(r,1)$\n",
    "     * draw a random uniform value between 0 and 1 , $t\\sim U(0,1)$. \n",
    "     * if $t<\\alpha$, accept $\\theta_\\text{new}$ as the new value of $\\theta$, otherwise reject it and keep $\\theta$ as the value. \n",
    "     \n",
    "The idea is that the chain will tend to move towards higher values of the posterior such that any infrence we peform will be more accurate as most of our samples will be around the maximum of the posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our proposal generator\n",
    "# a common choice is a Gaussian centered at the current value of theta\n",
    "def proposal(th):\n",
    "    return numpy.random.normal(th,1)\n",
    "\n",
    "# function to accept new proposal or reject it \n",
    "def accept_or_reject(th_new,th):  \n",
    "    r = posterior(th_new)/posterior(th)\n",
    "    if r > 1: \n",
    "        return th_new,True \n",
    "    else:\n",
    "        alpha = min([r,1])\n",
    "        t = numpy.random.uniform(0,1)\n",
    "        if t < alpha : \n",
    "            return th_new,True\n",
    "        else: return th,False\n",
    "\n",
    "init_th = proposal(3)\n",
    "accepted_mc_MH = []\n",
    "\n",
    "number_steps = 10000\n",
    "for i in range(number_steps) :\n",
    "    \n",
    "    th_new = proposal(init_th)\n",
    "    th_new,accept = accept_or_reject(th_new,init_th)\n",
    "    init_th = th_new\n",
    "    if accept: accepted_mc_MH.append(th_new)\n",
    "        \n",
    "# plot the accepted points vs the step\n",
    "plt.plot(range(len(accepted_mc_MH)),accepted_mc_MH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09dc860",
   "metadata": {},
   "source": [
    "Its usually a good idea to remove some first chunk of the markov chain since the initial part will depend on the initial value and the proposal function, meaning the distribution of the samples changes as the process continues. This is known as the *burn-in* period. We can just throw away the first 1000 points to remove this part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21e44d-8c60-4bd7-9ab2-87d6503eb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_mc_MH = accepted_mc_MH[1000:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0b2d2-0c25-42d0-9ad5-7796bfd83a1b",
   "metadata": {},
   "source": [
    "And now plot the results. Again, we can compare to the analytic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(accepted_mc_MH,density=True,fill=False,edgecolor='green',bins=25,label='Markov chain (MH)')\n",
    "plt.plot(thvals,post,color='red',label='Analytic')\n",
    "plt.legend()\n",
    "plt.xlabel(\"$\\\\theta$\")\n",
    "plt.ylabel(\"$p(\\\\theta|X)$\")\n",
    "plt.savefig(\"markovchainexample.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3194b0",
   "metadata": {},
   "source": [
    "Note again that the resulting distribution resembles the direct calculation. However this time, we have many more samples in the distribution since the generation is more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fraction of accepted samples - simple MC\",  float(len(accepted_mc))/len(mcprior))\n",
    "print(\"fraction of accepted samples - MC MH\",  float(len(accepted_mc_MH))/number_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ae355",
   "metadata": {},
   "source": [
    "It's usually a good idea to check that the calculation has converged. One way to check is to look at the history of the parameter values - in our case it looks like the chain doesn't wander into some bizarre region of the parameter values so seems ok. \n",
    "\n",
    "We can also check if the earlier part of the samples looks the same as the latter parts. For example, lets compare the first half of samples after the burn-in to the second half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cad65-b41d-4994-93b8-d3bda82cdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "halfpoint = int(len(accepted_mc_MH)/2)\n",
    "plt.hist(accepted_mc_MH[0:halfpoint],density=True,\n",
    "         fill=True,edgecolor='blue',bins=25,range=[-2,5],label='1st half')\n",
    "plt.hist(accepted_mc_MH[halfpoint:-1],density=True,\n",
    "         fill=False,edgecolor='red',bins=25,range=[-2,5],label='2nd half')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e60f8-03fd-4099-90ca-e731933b3d50",
   "metadata": {},
   "source": [
    "Of course, there are several packages out there that will perform markov chain mc for us based in `python`, `R`, or `c++` (eg see `pymc`, `MarkovChainMC` in `RooFit`...) etc. These will have routines for you to make these checks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
